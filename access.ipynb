{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5407956b",
   "metadata": {},
   "source": [
    "1.Voice Recognition:\n",
    "   -Use a speech recognition library (e.g., Google Cloud Speech-to-Text, CMUSphinx) to convert spoken commands to text.\n",
    "   -Capture audio input from a microphone or other audio source.\n",
    "   -Process the audio input and use the speech recognition library to convert it into text.\n",
    "   -Implement logic to interpret the recognized commands and take appropriate actions.\n",
    "   \n",
    "   \n",
    "2.Image Recognition:\n",
    "   -Use an image recognition library (e.g., OpenCV, TensorFlow) for eye verification or any other desired image recognition         tasks.\n",
    "   -Capture images from a camera or other image sources.\n",
    "    Process the images and use the image recognition library to perform eye verification or any other required tasks.\n",
    "    Implement logic to interpret the results of the image recognition and take appropriate actions.\n",
    "\n",
    "\n",
    "3.Access Control:\n",
    "   -Maintain a user database or some form of user information storage.\n",
    "   -Define an authentication mechanism to verify the admin's identity using voice and/or eye verification.\n",
    "   -Compare the recognized voice or eye data with the stored admin's data to grant or deny access.\n",
    "   -Implement appropriate access control measures based on the authentication result.\n",
    "\n",
    "\n",
    "4.Administration Tasks:\n",
    "   -Define a set of tasks that the admin can perform (e.g., updating user information, managing orders).\n",
    "   -Implement logic to receive and process admin commands using voice recognition.\n",
    "   -Use the authentication mechanism to verify that the command is issued by the admin.\n",
    "   -Execute the requested admin task based on the recognized command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72fdcb25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\sai\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\sai\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SpeechRecognition) (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sai\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sai\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sai\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sai\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84d7ac20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement engine (from versions: none)\n",
      "ERROR: No matching distribution found for engine\n"
     ]
    }
   ],
   "source": [
    "pip install engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6839e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_eye.xml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53144e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyAudio in c:\\users\\sai\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.13)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31f04855",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something...\n",
      "Recognized voice: Anirudh\n",
      "Eyes detected.\n",
      "Access granted as admin.\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import cv2\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize the speech recognition module\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Initialize the eye recognition module\n",
    "face_cascade = cv2.CascadeClassifier(r'F:\\admin\\haarcascade\\haarcascade_eye.xml')\n",
    "\n",
    "# Load admin data from a user database or other storage\n",
    "admin_voice_data = 'Anirudh'\n",
    "admin_eye_data = 'admin eye data'\n",
    "\n",
    "# Initialize the text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "\n",
    "\n",
    "# Voice recognition function\n",
    "def recognize_voice():\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Say something...\")\n",
    "        audio = r.listen(source)\n",
    "        try:\n",
    "            text = r.recognize_google(audio)\n",
    "            print(\"Recognized voice:\", text)\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Unable to recognize voice.\")\n",
    "            return None\n",
    "\n",
    "# Eye verification function\n",
    "def verify_eye(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    eyes = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    if len(eyes) > 0:\n",
    "        print(\"Eyes detected.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Eyes not detected.\")\n",
    "        return False\n",
    "\n",
    "# Access control function\n",
    "def access_control():\n",
    "    voice_text = recognize_voice()\n",
    "    eye_image = capture_eye_image()\n",
    "\n",
    "    if voice_text == admin_voice_data and verify_eye(eye_image):\n",
    "        print(\"Access granted as admin.\")\n",
    "        engine.say(\"Welcome, Access granted Anirudha!\")\n",
    "        engine.runAndWait()\n",
    "        # Perform admin tasks here\n",
    "        return False  # Stop the loop\n",
    "    else:\n",
    "        print(\"Access denied.\")\n",
    "        engine.say(\"Access required.\")\n",
    "        engine.runAndWait()\n",
    "        return True  # Continue the loop\n",
    "\n",
    "# Function to capture an image for eye verification\n",
    "def capture_eye_image():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    _, frame = cap.read()\n",
    "    cap.release()\n",
    "    return frame\n",
    "\n",
    "# Say the welcome message before starting the loop\n",
    "engine.say(\"Welcome, please enter the input\")\n",
    "engine.runAndWait()\n",
    "\n",
    "# Main loop\n",
    "while True:\n",
    "    if not access_control():\n",
    "        break  # Exit the loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1670fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e948fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6fae71",
   "metadata": {},
   "source": [
    "1.Voice Recognition:\n",
    "   -Use a speech recognition library (e.g., Google Cloud Speech-to-Text, CMUSphinx) to convert spoken commands to text.\n",
    "   -Capture audio input from a microphone or other audio source.\n",
    "   -Process the audio input and use the speech recognition library to convert it into text.\n",
    "   -Implement logic to interpret the recognized commands and take appropriate actions.\n",
    "   \n",
    "   \n",
    "2.Image Recognition:\n",
    "   -Use an image recognition library (e.g., OpenCV, TensorFlow) for eye verification or any other desired image recognition         tasks.\n",
    "   -Capture images from a camera or other image sources.\n",
    "    Process the images and use the image recognition library to perform eye verification or any other required tasks.\n",
    "    Implement logic to interpret the results of the image recognition and take appropriate actions.\n",
    "\n",
    "\n",
    "3.Access Control:\n",
    "   -Maintain a user database or some form of user information storage.\n",
    "   -Define an authentication mechanism to verify the admin's identity using voice and/or eye verification.\n",
    "   -Compare the recognized voice or eye data with the stored admin's data to grant or deny access.\n",
    "   -Implement appropriate access control measures based on the authentication result.\n",
    "\n",
    "\n",
    "4.Administration Tasks:\n",
    "   -Define a set of tasks that the admin can perform (e.g., updating user information, managing orders).\n",
    "   -Implement logic to receive and process admin commands using voice recognition.\n",
    "   -Use the authentication mechanism to verify that the command is issued by the admin.\n",
    "   -Execute the requested admin task based on the recognized command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab136d56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\sai\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\sai\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SpeechRecognition) (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sai\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sai\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sai\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sai\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "addb12eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement engine (from versions: none)\n",
      "ERROR: No matching distribution found for engine\n"
     ]
    }
   ],
   "source": [
    "pip install engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d578e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_eye.xml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d069153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyAudio in c:\\users\\sai\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.13)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca3ce432",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something...\n",
      "Recognized voice: Anirudh\n",
      "Eyes not detected.\n",
      "Access denied.\n",
      "Say something...\n",
      "Unable to recognize voice.\n",
      "Access denied.\n",
      "Say something...\n",
      "Recognized voice: Anirudh\n",
      "Eyes detected.\n",
      "Access granted as admin.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 61\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Main loop\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 61\u001b[0m     \u001b[43maccess_control\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 46\u001b[0m, in \u001b[0;36maccess_control\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m voice_text \u001b[38;5;241m==\u001b[39m admin_voice_data \u001b[38;5;129;01mand\u001b[39;00m verify_eye(eye_image):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess granted as admin.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m     \u001b[43mengine\u001b[49m\u001b[38;5;241m.\u001b[39msay(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWelcome, Anirudha!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m     engine\u001b[38;5;241m.\u001b[39mrunAndWait()\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# Perform admin tasks here\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'engine' is not defined"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the speech recognition module\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Initialize the eye recognition module\n",
    "face_cascade = cv2.CascadeClassifier(r'F:\\admin\\haarcascade\\haarcascade_eye.xml')\n",
    "\n",
    "# Load admin data from a user database or other storage\n",
    "admin_voice_data = 'Anirudh'\n",
    "admin_eye_data = 'admin eye data'\n",
    "\n",
    "# Voice recognition function\n",
    "def recognize_voice():\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Say something...\")\n",
    "        audio = r.listen(source)\n",
    "        try:\n",
    "            text = r.recognize_google(audio)\n",
    "            print(\"Recognized voice:\", text)\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Unable to recognize voice.\")\n",
    "            return None\n",
    "\n",
    "# Eye verification function\n",
    "def verify_eye(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    eyes = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    if len(eyes) > 0:\n",
    "        print(\"Eyes detected.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Eyes not detected.\")\n",
    "        return False\n",
    "\n",
    "# Access control function\n",
    "def access_control():\n",
    "    voice_text = recognize_voice()\n",
    "    eye_image = capture_eye_image()\n",
    "\n",
    "    if voice_text == admin_voice_data and verify_eye(eye_image):\n",
    "        print(\"Access granted as admin.\")\n",
    "        engine.say(\"Welcome, Anirudha!\")\n",
    "        engine.runAndWait()\n",
    "        # Perform admin tasks here\n",
    "    else:\n",
    "        print(\"Access denied.\")\n",
    "\n",
    "# Function to capture an image for eye verification\n",
    "def capture_eye_image():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    _, frame = cap.read()\n",
    "    cap.release()\n",
    "    return frame\n",
    "\n",
    "# Main loop\n",
    "while True:\n",
    "    access_control()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c853bd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f48b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
